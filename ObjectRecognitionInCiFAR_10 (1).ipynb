{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BR_DGLX1yebW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n"
      ],
      "metadata": {
        "id": "Ybisb2uWYJ8y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test  = tf.keras.utils.to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "-4aObP5ngxiy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "datagen.fit(X_train)"
      ],
      "metadata": {
        "id": "YwCyoV8yg0DK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimized Deeper CNN Model\n",
        "model = models.Sequential([\n",
        "    # Block 1\n",
        "    layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(32,32,3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    # Block 2\n",
        "    layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Dropout(0.35),\n",
        "\n",
        "    # Block 3\n",
        "    layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Dropout(0.4),\n",
        "\n",
        "    # Dense Layers\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IffnXb6IYOYT",
        "outputId": "bb39a852-da41-44a3-9d4b-d9556ce18db0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "RNOqMBHZYRQd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_accuracy', factor=0.5, patience=3, verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "8jK3DwuHg-A0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=64),\n",
        "    epochs=50,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[lr_scheduler]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcbT5oNDYVSN",
        "outputId": "c70da84f-bc25-478f-fe1c-e6e4986ec47d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 51ms/step - accuracy: 0.2769 - loss: 2.1485 - val_accuracy: 0.4467 - val_loss: 1.4800 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.4469 - loss: 1.5092 - val_accuracy: 0.4926 - val_loss: 1.4329 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 38ms/step - accuracy: 0.5294 - loss: 1.3141 - val_accuracy: 0.6118 - val_loss: 1.1262 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 39ms/step - accuracy: 0.5939 - loss: 1.1579 - val_accuracy: 0.6276 - val_loss: 1.1269 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 38ms/step - accuracy: 0.6338 - loss: 1.0587 - val_accuracy: 0.6763 - val_loss: 0.9344 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 39ms/step - accuracy: 0.6594 - loss: 0.9869 - val_accuracy: 0.6757 - val_loss: 0.9788 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 38ms/step - accuracy: 0.6804 - loss: 0.9354 - val_accuracy: 0.6771 - val_loss: 1.0119 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.6951 - loss: 0.8901 - val_accuracy: 0.7233 - val_loss: 0.7960 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 39ms/step - accuracy: 0.7086 - loss: 0.8574 - val_accuracy: 0.7421 - val_loss: 0.7660 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7246 - loss: 0.8115 - val_accuracy: 0.7649 - val_loss: 0.7013 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.7320 - loss: 0.7872 - val_accuracy: 0.7673 - val_loss: 0.6874 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.7410 - loss: 0.7669 - val_accuracy: 0.7644 - val_loss: 0.7086 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 39ms/step - accuracy: 0.7476 - loss: 0.7413 - val_accuracy: 0.7784 - val_loss: 0.6751 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 39ms/step - accuracy: 0.7567 - loss: 0.7244 - val_accuracy: 0.7574 - val_loss: 0.7090 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 38ms/step - accuracy: 0.7651 - loss: 0.7002 - val_accuracy: 0.7906 - val_loss: 0.6359 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 39ms/step - accuracy: 0.7710 - loss: 0.6835 - val_accuracy: 0.7735 - val_loss: 0.6788 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 39ms/step - accuracy: 0.7731 - loss: 0.6647 - val_accuracy: 0.8184 - val_loss: 0.5463 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7814 - loss: 0.6454 - val_accuracy: 0.7972 - val_loss: 0.6112 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.7860 - loss: 0.6334 - val_accuracy: 0.7881 - val_loss: 0.6637 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7897 - loss: 0.6183\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.7897 - loss: 0.6183 - val_accuracy: 0.8067 - val_loss: 0.5761 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.8017 - loss: 0.5801 - val_accuracy: 0.8274 - val_loss: 0.5240 - learning_rate: 5.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 38ms/step - accuracy: 0.8095 - loss: 0.5528 - val_accuracy: 0.8269 - val_loss: 0.5104 - learning_rate: 5.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.8120 - loss: 0.5490 - val_accuracy: 0.8314 - val_loss: 0.5074 - learning_rate: 5.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 39ms/step - accuracy: 0.8176 - loss: 0.5361 - val_accuracy: 0.8358 - val_loss: 0.5031 - learning_rate: 5.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.8201 - loss: 0.5295 - val_accuracy: 0.8309 - val_loss: 0.5081 - learning_rate: 5.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 39ms/step - accuracy: 0.8191 - loss: 0.5272 - val_accuracy: 0.8038 - val_loss: 0.5947 - learning_rate: 5.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.8236 - loss: 0.5237 - val_accuracy: 0.8380 - val_loss: 0.4930 - learning_rate: 5.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 39ms/step - accuracy: 0.8273 - loss: 0.5138 - val_accuracy: 0.8530 - val_loss: 0.4464 - learning_rate: 5.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 40ms/step - accuracy: 0.8237 - loss: 0.5090 - val_accuracy: 0.8389 - val_loss: 0.4838 - learning_rate: 5.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.8301 - loss: 0.5050 - val_accuracy: 0.8305 - val_loss: 0.5126 - learning_rate: 5.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8290 - loss: 0.4962\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 39ms/step - accuracy: 0.8290 - loss: 0.4962 - val_accuracy: 0.8439 - val_loss: 0.4673 - learning_rate: 5.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.8382 - loss: 0.4732 - val_accuracy: 0.8518 - val_loss: 0.4480 - learning_rate: 2.5000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 39ms/step - accuracy: 0.8390 - loss: 0.4643 - val_accuracy: 0.8508 - val_loss: 0.4483 - learning_rate: 2.5000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m781/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8396 - loss: 0.4672\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 40ms/step - accuracy: 0.8396 - loss: 0.4672 - val_accuracy: 0.8467 - val_loss: 0.4544 - learning_rate: 2.5000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 39ms/step - accuracy: 0.8440 - loss: 0.4593 - val_accuracy: 0.8595 - val_loss: 0.4263 - learning_rate: 1.2500e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.8445 - loss: 0.4547 - val_accuracy: 0.8541 - val_loss: 0.4384 - learning_rate: 1.2500e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 39ms/step - accuracy: 0.8519 - loss: 0.4357 - val_accuracy: 0.8609 - val_loss: 0.4195 - learning_rate: 1.2500e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.8479 - loss: 0.4443 - val_accuracy: 0.8555 - val_loss: 0.4352 - learning_rate: 1.2500e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 39ms/step - accuracy: 0.8478 - loss: 0.4400 - val_accuracy: 0.8617 - val_loss: 0.4111 - learning_rate: 1.2500e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 39ms/step - accuracy: 0.8505 - loss: 0.4391 - val_accuracy: 0.8620 - val_loss: 0.4120 - learning_rate: 1.2500e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.8519 - loss: 0.4305 - val_accuracy: 0.8554 - val_loss: 0.4361 - learning_rate: 1.2500e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 39ms/step - accuracy: 0.8517 - loss: 0.4341 - val_accuracy: 0.8683 - val_loss: 0.4000 - learning_rate: 1.2500e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.8531 - loss: 0.4279 - val_accuracy: 0.8606 - val_loss: 0.4180 - learning_rate: 1.2500e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 39ms/step - accuracy: 0.8519 - loss: 0.4325 - val_accuracy: 0.8648 - val_loss: 0.4034 - learning_rate: 1.2500e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8519 - loss: 0.4328\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.8519 - loss: 0.4328 - val_accuracy: 0.8636 - val_loss: 0.4142 - learning_rate: 1.2500e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.8524 - loss: 0.4296 - val_accuracy: 0.8614 - val_loss: 0.4189 - learning_rate: 6.2500e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.8566 - loss: 0.4193 - val_accuracy: 0.8666 - val_loss: 0.4117 - learning_rate: 6.2500e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8543 - loss: 0.4265\n",
            "Epoch 48: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 39ms/step - accuracy: 0.8543 - loss: 0.4265 - val_accuracy: 0.8634 - val_loss: 0.4151 - learning_rate: 6.2500e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.8568 - loss: 0.4174 - val_accuracy: 0.8667 - val_loss: 0.4063 - learning_rate: 3.1250e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.8548 - loss: 0.4209 - val_accuracy: 0.8671 - val_loss: 0.4057 - learning_rate: 3.1250e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(\"Test accuracy:\", round(test_acc * 100, 2), \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2Qiul1wYXrv",
        "outputId": "d5ac25f5-dd79-4bc4-829c-6d8a751340e5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - 3ms/step - accuracy: 0.8671 - loss: 0.4057\n",
            "Test accuracy: 86.71 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload image file\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "crFdvjt5XxRO",
        "outputId": "d42ebc5e-70a4-44fb-b952-31ad1c54f5a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8a2e2fde-d534-4a25-a940-74f6a4228ec9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8a2e2fde-d534-4a25-a940-74f6a4228ec9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dog.jpeg to dog (1).jpeg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get uploaded file path\n",
        "img_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Load image in CIFAR-10 format (32x32)\n",
        "img = image.load_img(img_path, target_size=(32, 32))\n",
        "\n",
        "# Display image\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.title(\"Uploaded Image\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WT27tDCCYA9m",
        "outputId": "beca0ddc-e709-49dd-a3cb-aa03732aac5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert to array and normalize\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array = img_array / 255.0\n"
      ],
      "metadata": {
        "id": "ZRRP9V_nYEWa"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-10 class names\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Make prediction\n",
        "predictions = model.predict(img_array)\n",
        "predicted_class = class_names[np.argmax(predictions)]\n",
        "confidence = np.max(predictions) * 100\n",
        "\n",
        "# Output prediction\n",
        "print(f\"Predicted Class: {predicted_class}\")\n",
        "print(f\"Confidence: {confidence:.2f}%\")\n"
      ],
      "metadata": {
        "id": "e2VzTwRLYHUL",
        "outputId": "b47ff7fa-ce3c-4ed5-d076-6c397dbb7943",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Predicted Class: dog\n",
            "Confidence: 98.67%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}